{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import sys, os, re, csv, codecs, numpy as np, pandas as pd\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('input_data/train.csv')\n",
    "test = pd.read_csv('input_data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_sentences_train = train[\"comment_text\"].fillna(\"_na_\").values\n",
    "# list_sentences_test = test[\"comment_text\"].fillna(\"_na_\").values\n",
    "list_sentences_train = train[\"comment_text\"].values\n",
    "list_sentences_test = test[\"comment_text\"].values\n",
    "full_data = np.concatenate((list_sentences_train, list_sentences_test), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters='!\"#$%&()+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'\n",
    "tokenizer = Tokenizer(filters=filters)\n",
    "tokenizer.fit_on_texts(list(full_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tokenizer.texts_to_sequences(full_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_index_map = {v: k for k, v in tokenizer.word_index.iteritems()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(X)):\n",
    "    for j in range(len(X[i])):\n",
    "        X[i][j] = inv_index_map[X[i][j]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let X be a list of tokenized texts (i.e. list of lists of tokens)\n",
    "model = gensim.models.Word2Vec(X, size=100)\n",
    "w2v = dict(zip(model.wv.index2word, model.wv.syn0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.02902227,  0.0466614 , -0.08466748,  0.12051544, -0.06433592,\n",
       "       -0.03288721, -0.14683121,  0.04867191,  0.06837261,  0.03225236,\n",
       "       -0.07308079,  0.02407386, -0.0793974 ,  0.01340642,  0.0824607 ,\n",
       "        0.04828719,  0.03394204, -0.02036875,  0.01932808, -0.05353895,\n",
       "       -0.03019029,  0.02412271,  0.03366189,  0.15340912,  0.02320395,\n",
       "        0.01887658,  0.00354106, -0.0318832 , -0.05222381, -0.11271504,\n",
       "       -0.06513771,  0.02997163,  0.02248435, -0.00599823,  0.07412851,\n",
       "        0.05214727,  0.04109577,  0.04019812, -0.01246289, -0.02900722,\n",
       "       -0.25325587, -0.01644839, -0.04608771,  0.0491109 ,  0.08025518,\n",
       "       -0.05722439,  0.05633632, -0.09640583, -0.0551931 ,  0.08521138,\n",
       "       -0.00065839,  0.05352844, -0.04572744, -0.01317497, -0.14824072,\n",
       "       -0.0488035 , -0.08802962,  0.00334372, -0.00858681, -0.15940742,\n",
       "        0.01403885, -0.01651752, -0.06541128, -0.0941546 , -0.01934172,\n",
       "       -0.00409854, -0.05706808,  0.04383071,  0.00130798, -0.04570565,\n",
       "        0.0361319 ,  0.02699611, -0.18992464,  0.03848457, -0.09684239,\n",
       "       -0.04601657,  0.07436321, -0.02728014, -0.02688141,  0.0940657 ,\n",
       "       -0.02159126,  0.03504126, -0.04573165, -0.12340163, -0.07456657,\n",
       "       -0.08913082,  0.01222411, -0.05029052,  0.15832014, -0.00342326,\n",
       "       -0.11438128,  0.01899829, -0.02533148, -0.03565726,  0.0088162 ,\n",
       "       -0.08805765,  0.02752735,  0.02714424,  0.07714128, -0.16542037],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v[w2v.keys()[34440]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
